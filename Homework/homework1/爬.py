import requests
import pandas as pd
import time
import json # å¯¼å…¥jsonæ¨¡å—ï¼Œç”¨äºç¾åŒ–æ‰“å°JSON

def scrape_full_rich_list():
    """
    é€šè¿‡å¾ªç¯è°ƒç”¨APIæ¥è·å–å®Œæ•´çš„èƒ¡æ¶¦æ¦œå•æ•°æ®ï¼Œå¹¶è‡ªåŠ¨å¤„ç†åˆ†é¡µã€‚
    """
    
    base_api_url = "https://www.hurun.net/zh-CN/Rank/HsRankDetailsList?num=ODBYW2BI&search=&offset={offset}&limit={limit}"
    
    limit = 20
    offset = 0
    
    all_records = []
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'application/json, text/plain, */*',
        'Referer': 'https://www.hurun.net/zh-CN/Rank/HsRankDetails?pagetype=rich',
    }

    print("--- å¼€å§‹çˆ¬å–å®Œæ•´æ¦œå•ï¼ˆè‡ªåŠ¨ç¿»é¡µï¼‰---")
    
    while True:
        current_url = base_api_url.format(offset=offset, limit=limit)
        
        page_num = (offset // limit) + 1
        print(f"\næ­£åœ¨çˆ¬å–ç¬¬ {page_num} é¡µæ•°æ®...")
        print(f"URL: {current_url}")
        
        try:
            response = requests.get(current_url, headers=headers, timeout=20)
            response.raise_for_status() # æ£€æŸ¥HTTPçŠ¶æ€ç ï¼Œå¦‚æœä¸æ˜¯200åˆ™æŠ›å‡ºå¼‚å¸¸
            data = response.json()

            # --- è°ƒè¯•æ­¥éª¤ï¼šæ‰“å°å®Œæ•´çš„JSONå“åº”ä»¥ç¡®è®¤ç»“æ„ ---
            # è¯·åœ¨é‡åˆ°é—®é¢˜æ—¶å–æ¶ˆæ³¨é‡Šä¸‹é¢ä¸¤è¡Œï¼ŒæŸ¥çœ‹APIè¿”å›çš„å®é™…JSONç»“æ„
            # print("--- åŸå§‹JSONå“åº”ï¼ˆç”¨äºè°ƒè¯•ï¼‰---")
            # print(json.dumps(data, indent=2, ensure_ascii=False)) 
            # print("----------------------------")
            # --- è°ƒè¯•ç»“æŸ ---

            # æ ¹æ®æ‚¨æä¾›çš„JSONç‰‡æ®µï¼Œå‡å®šå®Œæ•´çš„å¯Œè±ªåˆ—è¡¨ä»åœ¨ 'data' -> 'rows' è·¯å¾„ä¸‹
            # ä½†æˆ‘ä»¬ä¼šæ›´è°¨æ…åœ°æ£€æŸ¥æ¯ä¸€ä¸ªå±‚çº§
            
            if 'rows' in data: # ç›´æ¥æ£€æŸ¥æ ¹çº§åˆ«æ˜¯å¦æœ‰ 'rows' é”®
                new_records = data['rows'] # ç›´æ¥ä»æ ¹çº§åˆ«è·å– 'rows'
                if not isinstance(new_records, list):
                    print(f"âŒ é”™è¯¯: 'rows' å­˜åœ¨ï¼Œä½†å®ƒä¸æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚å®é™…ç±»å‹: {type(new_records)}")
                    break # æ•°æ®ç»“æ„ä¸ç¬¦åˆé¢„æœŸï¼Œé€€å‡º
            else:
                print(f"âŒ é”™è¯¯: JSONå“åº”ä¸­æœªæ‰¾åˆ° 'rows' é”®ã€‚")
                print(f"æ ¹çº§åˆ«é”®: {list(data.keys())}") # æ‰“å°æ ¹çº§åˆ«çš„æ‰€æœ‰é”®ï¼Œæ–¹ä¾¿æ’æŸ¥
                break # ç»“æ„ä¸å¯¹ï¼Œé€€å‡ºå¾ªç¯

            # --- åˆ¤æ–­æ˜¯å¦åˆ°è¾¾æœ€åä¸€é¡µ ---
            if not new_records:
                print("\nâœ… æ•°æ®å…¨éƒ¨åŠ è½½å®Œæ¯•ï¼Œæ²¡æœ‰æ–°å†…å®¹äº†ã€‚")
                break # å¦‚æœè¿”å›çš„æ•°æ®ä¸ºç©ºï¼Œè¯´æ˜å·²ç»çˆ¬å®Œäº†ï¼Œé€€å‡ºå¾ªç¯
                
            print(f"âœ… æˆåŠŸè·å– {len(new_records)} æ¡æ–°è®°å½•ã€‚")
            all_records.extend(new_records)
            
            # å‡†å¤‡ä¸‹ä¸€é¡µ
            offset += limit
            
            # ç¤¼è²Œæ€§åœ°æš‚åœä¸€ä¸‹
            time.sleep(0.5)

        except requests.exceptions.RequestException as e:
            print(f"âŒ é”™è¯¯: è¯·æ±‚ç¬¬ {page_num} é¡µæ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯æˆ–HTTPé”™è¯¯: {e}")
            break # ç½‘ç»œå‡ºé”™äº†ï¼Œä¹Ÿé€€å‡ºå¾ªç¯
        except json.JSONDecodeError as e:
            print(f"âŒ é”™è¯¯: æ— æ³•è§£æç¬¬ {page_num} é¡µçš„JSONå“åº”: {e}")
            print(f"å°è¯•è·å–çš„å“åº”æ–‡æœ¬: {response.text[:500]}...") # æ‰“å°éƒ¨åˆ†å“åº”æ–‡æœ¬
            break # JSONè§£æå¤±è´¥ï¼Œé€€å‡ºå¾ªç¯
        except Exception as e:
            print(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            break


    if not all_records:
        print("\n--- ä»»åŠ¡å¤±è´¥ ---")
        print("æœªèƒ½çˆ¬å–åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–APIæ˜¯å¦å·²å˜æ›´ã€‚")
        return

    print("\n--- æ•°æ®æ•´åˆ ---")
    print(f"æ€»è®¡çˆ¬å–åˆ° {len(all_records)} æ¡è®°å½•ã€‚")
    df = pd.DataFrame(all_records)
    print("æ­£åœ¨å°†æ•°æ®è½¬æ¢ä¸ºè¡¨æ ¼...")

    output_filename = "èƒ¡æ¶¦ç™¾å¯Œæ¦œå®Œæ•´æ•°æ®.csv"
    df.to_csv(output_filename, index=False, encoding='utf-8-sig')

    print(f"\nğŸ‰ğŸ‰ğŸ‰ ä»»åŠ¡åœ†æ»¡å®Œæˆï¼ ğŸ‰ğŸ‰ğŸ‰")
    print(f"æ‰€æœ‰æ•°æ®å·²ä¿å­˜è‡³æ–‡ä»¶: '{output_filename}'")
    
    print("\næ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
    print(df.head())

# --- ç¨‹åºä¸»å…¥å£ ---
if __name__ == '__main__':
    scrape_full_rich_list()